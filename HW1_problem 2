class ComplexMLP(nn.Module):
    def __init__(self, input_size=3072, num_classes=10):
        super(ComplexMLP, self).__init__()
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(input_size, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_classes)
        )
        
    def forward(self, x):
        return self.model(x)
complex_model = ComplexMLP().to(device)
criterion_complex = nn.CrossEntropyLoss()
optimizer_complex = optim.Adam(complex_model.parameters(), lr=0.001)
num_epochs = 20

train_losses_complex = []
train_accuracies_complex = []
val_accuracies_complex = []

for epoch in range(num_epochs):
    complex_model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer_complex.zero_grad()
        outputs = complex_model(images)
        loss = criterion_complex(outputs, labels)
        loss.backward()
        optimizer_complex.step()
        
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
    epoch_loss = running_loss / total
    epoch_train_acc = correct / total
    train_losses_complex.append(epoch_loss)
    train_accuracies_complex.append(epoch_train_acc)
    
    # Validation
    complex_model.eval()
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = complex_model(images)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()
    epoch_val_acc = val_correct / val_total
    val_accuracies_complex.append(epoch_val_acc)
    
    print(f"[Complex] Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, Val Acc: {epoch_val_acc:.4f}")
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(train_losses_complex, label="Train Loss (Complex)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Complex Model: Training Loss")
plt.legend()

plt.subplot(1,2,2)
plt.plot(train_accuracies_complex, label="Train Acc (Complex)")
plt.plot(val_accuracies_complex, label="Val Acc (Complex)")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Complex Model: Train & Val Accuracy")
plt.legend()

plt.show()
complex_model.eval()
all_labels_complex = []
all_preds_complex = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = complex_model(images)
        _, predicted = torch.max(outputs, 1)
        all_labels_complex.extend(labels.cpu().numpy())
        all_preds_complex.extend(predicted.cpu().numpy())

precision_complex = precision_score(all_labels_complex, all_preds_complex, average='macro')
recall_complex = recall_score(all_labels_complex, all_preds_complex, average='macro')
f1_complex = f1_score(all_labels_complex, all_preds_complex, average='macro')
cm_complex = confusion_matrix(all_labels_complex, all_preds_complex)

print("Complex Model - Test Precision: {:.4f}".format(precision_complex))
print("Complex Model - Test Recall: {:.4f}".format(recall_complex))
print("Complex Model - Test F1 Score: {:.4f}".format(f1_complex))
print("Complex Model - Confusion Matrix:\n", cm_complex)
